# Самостоятельная работа №3
# Предварительный анализ данных:
1. Проверка на пропуски ![image](https://user-images.githubusercontent.com/93386717/207188455-cb520538-9942-4ddc-992e-0a3fb549fe23.png)  
2. Описательные статистики для непрерывных переменных. Вывод: значения объясняющих переменных как положительные, так и отрицательные, масштабы измерения отличаются. Для работы с методами снижения размерности и регуляризации понадобится стандартизация значений.
# Визуализация разброса переменных внутри классов:
1. Поскольку в наборе данных 23 объясняющих переменных, и большинство непрерывные, анализ матричного графика разброса будет затруднительным. Построим коробчатые диаграммы для объясняющих переменных, чтобы сравнить средние уровни и разброс по классам.![image](https://user-images.githubusercontent.com/93386717/207189561-df5abeeb-a5dd-43ea-bdcb-c1dd4a8300d6.png)![image](https://user-images.githubusercontent.com/93386717/207189680-871e9c2a-1aab-4d35-9403-789d4888f382.png) ![image](https://user-images.githubusercontent.com/93386717/207189777-704e8184-c8ca-4852-b04e-04564141fd58.png) ![image](https://user-images.githubusercontent.com/93386717/207189911-0d748ae9-da48-4fb6-a99f-10888ace526d.png) ![image](https://user-images.githubusercontent.com/93386717/207190010-cde384ec-2af2-40d6-9c77-b308845dedad.png)
2. На графиках отличие в медианах и разбросе между классами прослеживается мало где. Существует большое количество аномальных значений. Это говорит о том, классы по зависимой переменной y плохо разделяются по всем объясняющим переменным.
# Корреляционный анализ:
1. ![image](https://user-images.githubusercontent.com/93386717/207190483-865eb05c-caf0-44d9-b12d-bcd2a84b7b8d.png)
# Снижение размерности:
1. Рассмотрим метод снижения размерности: регрессия на главные компоненты (PCR) Требуется предварительной стандартизация переменных.
2. ![image](https://user-images.githubusercontent.com/93386717/207191039-657c138c-587f-43e0-8833-e31ba04e5652.png)
3. ![image](https://user-images.githubusercontent.com/93386717/207191177-5dc1def5-b09d-4617-90cb-2113bf136498.png)
# Методы сжатия:
# Ридж-регрессия
1. Функция LogisticRegression() умеет работать с мультиклассовой классификацией, используя при оценке параметров подход один класс против остальных. Построим ридж на наших данных.
2. ![image](https://user-images.githubusercontent.com/93386717/207191730-081525c0-834f-4ecc-90a7-491b0ebd822a.png)
3. ![image](https://user-images.githubusercontent.com/93386717/207191870-ea73fc70-150e-40cc-b1fe-68e27f87f9e7.png)
# Прогноз:
Все модели показывают высокую точность по показателю , при этом самой точной оказывается ридж-регрессия. Сделаем прогноз на отложенные наблюдения.
Итак, методом логистической регрессии со сжатием коэффициенты с L2-регуляризацией мы получили значение f1-score 0,88 для 0 класса и 0,34 для 1 класса. Это очень плохие результаты, в пространстве этих объясняющих переменных предсказывание невозможно. Высокое попадание для класса 0 связано с его большим объёмом в выборке. Если возвращаться к графику ГК по РСА и рассмотреть отдельно оба класса, видно, что на самом деле за скоплением оранжевых точек (1 класс) скрывается большое количество зелённых (0 класс).



